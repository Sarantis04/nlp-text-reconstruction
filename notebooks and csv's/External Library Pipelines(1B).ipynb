{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f129843-8083-4469-b6ec-9dcc22096ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch nltk protobuf pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967ae665-014b-40a0-ac97-7f2511d18fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\nlp2025\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from nltk import sent_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942982fe-7b6e-4d34-91a8-dc6be1d41e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in\n",
    "our lives. Hope you too, to enjoy it as my deepest wishes.\n",
    "Thank your message to show our words to the doctor, as his next contract checking, to all of us.\n",
    "I got this message to see the approved message. In fact, I have received the message from the\n",
    "professor, to show me, this, a couple of days ago. I am very appreciated the full support of the\n",
    "professor, for our Springer proceedings publication\"\"\"\n",
    "\n",
    "text2 = \"\"\"During our final discuss, I told him about the new submission — the one we were waiting since\n",
    "last autumn, but the updates was confusing as it not included the full feedback from reviewer or\n",
    "maybe editor?\n",
    "Anyway, I believe the team, although bit delay and less communication at recent days, they really\n",
    "tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance\n",
    "and efforts until the Springer link came finally last week, I think.\n",
    "Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before\n",
    "he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so.\n",
    "Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future\n",
    "targets\"\"\"\n",
    "\n",
    "texts = [text1, text2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca9e29d-2e64-4521-87a5-9e5d4aa888e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "first = pipeline(\"text2text-generation\", model=\"vennify/t5-base-grammar-correction\")\n",
    "\n",
    "second = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "third = pipeline(\"text2text-generation\", model=\"prithivida/grammar_error_correcter_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf65b3be-6ab4-4a64-8496-628f3534deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Text 1 Rewrites ---\n",
      "\n",
      "Original text Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in\n",
      "our lives. Hope you too, to enjoy it as my deepest wishes.\n",
      "Thank your message to show our words to the doctor, as his next contract checking, to all of us.\n",
      "I got this message to see the approved message. In fact, I have received the message from the\n",
      "professor, to show me, this, a couple of days ago. I am very appreciated the full support of the\n",
      "professor, for our Springer proceedings publication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but your input_length is only 117. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=58)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Model Grammar Correction (sentence by sentence):\n",
      " Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safety and great in our lives. Hope you too, to enjoy it as my deepest wishes. Thank you for your message to show our words to the doctor, as his next contract checking, to all of us. I got this message to see the approved message. In fact, I have received the message from the professor, to show me, this, a couple of days ago. I am very appreciated the full support of the professor, for our Springer proceedings publication. \n",
      "\n",
      "Second Model Summarization (full text):\n",
      "  It is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives, hope you too, to enjoy it as my deepest wishes . I am very appreciated the full support of the . full support . for our Springer proceedings publication . I got this message to see the approved message . \n",
      "\n",
      "Third Model Grammar Correction (sentence by sentence):\n",
      " Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives. Hope you too, to enjoy it as my deepest wishes. Thank you for your message to show our words to the doctor, as his next contract checks, to all of us. I got this message to see the approved message. In fact, I have received the message from the professor, to show me, this, a couple of days ago. I am very grateful for the full support of the professor, for our Springer proceedings publication. \n",
      "\n",
      "\n",
      "--- Text 2 Rewrites ---\n",
      "\n",
      "Original text During our final discuss, I told him about the new submission — the one we were waiting since\n",
      "last autumn, but the updates was confusing as it not included the full feedback from reviewer or\n",
      "maybe editor?\n",
      "Anyway, I believe the team, although bit delay and less communication at recent days, they really\n",
      "tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance\n",
      "and efforts until the Springer link came finally last week, I think.\n",
      "Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before\n",
      "he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so.\n",
      "Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future\n",
      "targets\n",
      "First Model Grammar Correction (sentence by sentence):\n",
      " During our final discuss, I told him about the new submission — the one we were waiting for since last autumn, but the updates were confusing as it not included the full feedback from reviewer or maybe editor. Anyway, I believe the team, although a bit delayed and less communication at recent days, they really tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plans for the acknowledgments section edit before he sends again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets. \n",
      "\n",
      "Second Model Summarization (full text):\n",
      "  The Springer link finally came finally last week, I think. We should be grateful, I mean all of us, for the acceptance efforts until the Springer link came finally . I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation . \n",
      "\n",
      "Third Model Grammar Correction (sentence by sentence):\n",
      " During our final discuss, I told him about the new submission — the one we were waiting for since last autumn, but the updates were confusing as it did not include the full feedback from reviewer or maybe editor? Anyway, I believe the team, although a bit delay and less communication in recent days, they really tried their best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plans for the acknowledgments section edit before he sends again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets. \n",
      "\n",
      "✅ Results saved to pipeline_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i, txt in enumerate(texts, start=1):\n",
    "    print(f\"\\n--- Text {i} Rewrites ---\\n\")\n",
    "\n",
    "    print(\"Original text\",texts[i-1])\n",
    "    \n",
    "    sentences = sent_tokenize(txt)\n",
    "    first_corrected = []\n",
    "    for s in sentences:\n",
    "        out = first(s)\n",
    "        first_corrected.append(out[0]['generated_text'])\n",
    "    first_corrected_text = \" \".join(first_corrected)\n",
    "    print(\"First Model Grammar Correction (sentence by sentence):\\n\", first_corrected_text, \"\\n\")\n",
    "    \n",
    "    second_output = second(txt)\n",
    "    print(\"Second Model Summarization (full text):\\n\", second_output[0]['summary_text'], \"\\n\")\n",
    "    \n",
    "    third_corrected = []\n",
    "    for s in sentences:\n",
    "        out = third(s)\n",
    "        third_corrected.append(out[0]['generated_text'])\n",
    "    third_corrected_text = \" \".join(third_corrected)\n",
    "    print(\"Third Model Grammar Correction (sentence by sentence):\\n\", third_corrected_text, \"\\n\")\n",
    "\n",
    "    results.append({\n",
    "        \"Text_ID\": i,\n",
    "        \"Original_Text\": txt,\n",
    "        \"First_Model_Grammar\": first_corrected_text,\n",
    "        \"Second_Model_Summary\": second_output[0]['summary_text'],\n",
    "        \"Third_Model_Grammar\": third_corrected_text\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.to_csv(\"pipeline_outputs.csv\", index=False)\n",
    "\n",
    "print(\"✅ Results saved to pipeline_outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac76d0-ab45-44d7-a64e-8de95ee4ad45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp2025)",
   "language": "python",
   "name": "nlp2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
